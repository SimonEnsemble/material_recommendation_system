### A Pluto.jl notebook ###
# v0.12.20

using Markdown
using InteractiveUtils

# ‚ïî‚ïê‚ï° 92083d94-5b82-11eb-2274-ed62139bbf2d
begin
	using LowRankModels, CSV, DataFrames, PyPlot, Statistics, Distributions, StatsBase, Printf, UMAP, PyCall
	using ScikitLearn.CrossValidation: train_test_split
	PyPlot.matplotlib.style.use("https://gist.githubusercontent.com/JonnyCBB/c464d302fefce4722fe6cf5f461114ea/raw/64a78942d3f7b4b5054902f2cee84213eaff872f/matplotlibrc")
	# PyPlot.matplotlib.style.use("https://raw.githubusercontent.com/garrettj403/SciencePlots/master/styles/science.mplstyle")
	adjustText = pyimport("adjustText")
end

# ‚ïî‚ïê‚ï° ae415fa4-5b82-11eb-0051-072097bb0439
md"# read in data"

# ‚ïî‚ïê‚ï° b3deec9e-5b82-11eb-0e37-abd2ac9d4b44
begin
	df = CSV.read("aiida_ads_data_oct20.csv", DataFrame)
	
	# log-10 transform the henry coefficients.
	for henry_col in Symbol.(["h2o_henry", "h2s_henry", "xe_henry", "kr_henry"])
	    # convert units from mol/(kg-Pa) to mol/(kg-bar)
	    df[!, henry_col] = 1e5 * df[:, henry_col]
	    # log-10 transform
	    df[!, henry_col] = log10.(df[:, henry_col])
	end
	
	first(df, 10)
end

# ‚ïî‚ïê‚ï° bf9ed538-5b82-11eb-1198-3d35a209c5c0
md"# construct material-property matrix"

# ‚ïî‚ïê‚ï° c5d42b2e-5b82-11eb-0631-35efb6b0800c
begin
	properties = ["o2_5bar", 
	              "o2_140bar", 
	              "co2_0.001bar", 
	              "co2_30bar", 
	              "n2_0.001bar", 
	              "n2_30bar", 
	              "h2_77K_5bar", 
	              "h2_77K_100bar", 
	              "h2_298K_5bar",
	              "h2_298K_100bar", 
	              "h2o_henry", 
	              "h2s_henry",
	              "xe_henry",
	              "kr_henry",
	              "ch4_65bar",
	              "ch4_5.8bar"
	              ]
	
	prop_to_label = Dict("o2_5bar"        => L"O$_2$" * "\n(298 K, 5 bar)", 
	                     "o2_140bar"      => L"O$_2$" * "\n(298 K, 140 bar)", 
	                     "co2_0.001bar"   => L"CO$_2$" * "\n(300 K, 0.001 bar)", 
	                     "co2_30bar"      => L"CO$_2$" * "\n(300 K, 30 bar)", 
	                     "n2_0.001bar"    => L"N$_2$" * "\n(300 K, 0.001 bar)", 
	                     "n2_30bar"       => L"N$_2$" * "\n(300 K, 30 bar)", 
	                     "h2_77K_5bar"    => L"H$_2$" * "\n(77 K, 5 bar)", 
	                     "h2_77K_100bar"  => L"H$_2$" * "\n(77 K, 100 bar)", 
	                     "h2_298K_5bar"   => L"H$_2$" * "\n(298 K, 5 bar)", 
	                     "h2_298K_100bar" => L"H$_2$" * "\n(298 K, 100 bar)", 
	                     "h2o_henry"      => L"H$_2$O Henry" * "\n(300 K)", 
	                     "h2s_henry"      => L"H$_2$S Henry" * "\n(300 K)", 
	                     "xe_henry"       => "Xe Henry\n (300 K)", 
	                     "kr_henry"       => "Kr Henry\n (300 K)", 
	                     "ch4_65bar"      => L"CH$_4$" * "\n(298 K, 65 bar)", 
	                     "ch4_5.8bar"     => L"CH$_4$" * "\n(298 K, 5.8 bar)"
	                    )
	
	prop_to_label2 = Dict("o2_5bar"        => L"O$_2$" * "\n298 K\n5 bar", 
						 "o2_140bar"      => L"O$_2$" * "\n298 K\n140 bar", 
						 "co2_0.001bar"   => L"CO$_2$" * "\n300 K\n0.001 bar", 
						 "co2_30bar"      => L"CO$_2$" * "\n300 K\n30 bar", 
						 "n2_0.001bar"    => L"N$_2$" * "\n300 K\n0.001 bar", 
						 "n2_30bar"       => L"N$_2$" * "\n300 K\n30 bar", 
						 "h2_77K_5bar"    => L"H$_2$" * "\n77 K\n5 bar", 
						 "h2_77K_100bar"  => L"H$_2$" * "\n77 K\n100 bar", 
						 "h2_298K_5bar"   => L"H$_2$" * "\n298 K\n5 bar", 
						 "h2_298K_100bar" => L"H$_2$" * "\n298 K\n100 bar", 
						 "h2o_henry"      => L"H$_2$O Henry" * "\n300 K", 
						 "h2s_henry"      => L"H$_2$S Henry" * "\n300 K", 
						 "xe_henry"       => "Xe Henry\n300 K", 
						 "kr_henry"       => "Kr Henry\n300 K", 
						 "ch4_65bar"      => L"CH$_4$" * "\n298 K\n65 bar", 
						 "ch4_5.8bar"     => L"CH$_4$" * "\n298 K\n5.8 bar"
						)

	const materials = map(x -> split(x, ".cif")[1], df[:, :cof])
	const n_m = length(materials)
	const n_p = length(properties)
	# material property matrix
	const A_complete_unnormalized = convert(Matrix, df[:, properties])
	
	# normalize columns
	A_n = deepcopy(A_complete_unnormalized)
	for i = 1:n_p
		A_n[:, i] = (A_n[:, i] .- mean(A_n[:, i])) ./ std(A_n[:, i])
	end
	# dataframe form
	df_n = DataFrame()
	for i = 1:n_p
		df_n[:, prop_to_label2[properties[i]]] = A_n[:, i]
	end
	CSV.write("normalized_props.csv", df_n)
	df_n
end

# ‚ïî‚ïê‚ï° 6713990c-5b8d-11eb-2196-7182f36cad59
md"# simulate data collection"

# ‚ïî‚ïê‚ï° 2931005c-5b8d-11eb-2375-5dacf441be72
# Œ∏: target fraction observed values
function sim_data_collection(Œ∏::Float64)
    distn = Bernoulli(Œ∏) # for observing it
    A = zeros(Union{Float64, Missing}, n_m, n_p)
	for m = 1:n_m
		for p = 1:n_p
			if rand(distn)
				A[m, p] = A_complete_unnormalized[m, p]
			else
				A[m, p] = missing
			end
		end
	end
	Œ∏_true = 1.0 - sum(ismissing.(A)) / (n_m * n_p)
    return A, Œ∏_true
end

# ‚ïî‚ïê‚ï° a21ac3b8-5ba1-11eb-2d70-bdf4b395f563
function ids_obs_and_unobs(A::Array{Union{Float64, Missing}, 2})
	ids_obs = observations(A) # returns tuple of observations
	ids_not_obs = [(i, j) for i=1:size(A)[1], j=1:size(A)[2] if !((i,j) in ids_obs)][:]
	return ids_obs, ids_not_obs
end

# ‚ïî‚ïê‚ï° 1d363324-5b8f-11eb-2c78-6980a0d5f110
md"# normalization of columns"

# ‚ïî‚ïê‚ï° 2366b3cc-5b8f-11eb-07e4-61cbc97d5480
function normalize!(A::Array{Union{Float64, Missing}, 2})
	Œºs = zeros(n_p)
	œÉs = zeros(n_p)
    for p = 1:n_p
        ids_obs = .! ismissing.(A[:, p])
		Œºs[p] = mean(A[ids_obs, p])
		œÉs[p] = std(A[ids_obs, p])
        A[:, p] .= (A[:, p] .- Œºs[p]) ./ œÉs[p]
    end
	return Œºs, œÉs
end

# ‚ïî‚ïê‚ï° 6236b296-5f60-11eb-3aa7-5188433b3906
md"# matrix viz"

# ‚ïî‚ïê‚ï° 5ae47630-5f64-11eb-39f8-654f8d277674
function viz_matrix(A::Array{Union{Float64, Missing}, 2})
	norm = PyPlot.matplotlib.colors.Normalize(vmin=-4.0, vmax=4.0)
	cmap = PyPlot.matplotlib.cm.get_cmap("PiYG") # diverging
	
	# mapping adsorption properties to colors
	function a_to_color(a::Union{Float64, Missing})
		if ismissing(a)
			return (0.5, 0.5, 0.5, 1.0)
		else
			return cmap(norm(a))
		end
	end
	
	figure(figsize=(4, 15))
	ax = gca()
	is = imshow(a_to_color.(A))
	xlabel("gas\nadsorption\nproperties")
	ylabel("COFs")
	xticks([])
	yticks([])
	ylim([-0.5, size(A)[1]-0.5])
	xlim([-0.5, size(A)[2]-0.5])
	colorbar(PyPlot.matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap),
		label=L"$A_{ij}$ (normalized)", extend="both", shrink=0.4)
	tight_layout()
	savefig("matrix_example.pdf", format="pdf")
	gcf()
end

# ‚ïî‚ïê‚ï° 6ef474cc-5b90-11eb-2fe2-87bc7b48f5b7
md"# fit low rank model"

# ‚ïî‚ïê‚ï° 8a3c55ae-5ba4-11eb-3354-f9a8feaa7e91
struct HyperParam
	k::Int
	Œª::Float64
end

# ‚ïî‚ïê‚ï° 1d745ea2-5ba5-11eb-274a-4ff7a65b0cb6
struct ValidationRun
	hyper_param::HyperParam
	rmsd::Float64
end

# ‚ïî‚ïê‚ï° cc771288-5ba6-11eb-1792-9dfc54c58a8c
function min_rmsd(vrs::Array{ValidationRun, 1})
	da_best = vrs[1]
	for i = 2:length(vrs)
		if vrs[i].rmsd < da_best.rmsd
			da_best = vrs[i]
		end
	end
	return da_best
end

# ‚ïî‚ïê‚ï° f7158eea-5ba4-11eb-17cc-d57c477cec39
function hp_grid(ks::Array{Int, 1}, Œªs::Array{Float64, 1})
	hps = HyperParam[]
	for k in ks
		for Œª in Œªs
			push!(hps, HyperParam(k, Œª))
		end
	end
	return hps
end

# ‚ïî‚ïê‚ï° 8152d710-5b90-11eb-39f5-45d81aa298ab
# k = rank of matrix
# Œª = regularization param
# obs = which observations we train on.
# gotta pass the transpose for the bias to work.
function fit_glrm(At::Array{Union{Float64, Missing}, 2}, 
		          hp::HyperParam,
		          obs::Array{Tuple{Int64,Int64}, 1})
	# quadratic regularizors
    rp = QuadReg(hp.Œª)
    rm = QuadReg(hp.Œª * n_p / n_m)
	# this should be the transpose...
	@assert size(At) == (n_p, n_m)
	
	# A = M' P
	# At = P' M
	#   so here X is the analogy of P; Y is the analogy of M
    glrm = GLRM(At, QuadLoss(), rp, rm, hp.k+1, obs=obs, offset=true)
#    init_svd!(glrm)
    P, M, ch = fit!(glrm)
    @assert size(P) == (hp.k + 1, n_p)
    @assert size(M) == (hp.k + 1, n_m)

    @assert isapprox(impute(glrm), P' * M)
    return P, M, glrm, ch
end

# ‚ïî‚ïê‚ï° 21995e36-5f69-11eb-0a95-13d0136099df
function fit_bias_only_glrm(At::Array{Union{Float64, Missing}, 2},
		                     obs::Array{Tuple{Int64,Int64}, 1})
	hp = HyperParam(0, 0.0)
	return fit_glrm(At, hp, obs)
end

# ‚ïî‚ïê‚ï° e2dd554c-5baf-11eb-1b49-654d19bedecc
md"# for evaluating the glrm"

# ‚ïî‚ïê‚ï° 168d4c44-5bb3-11eb-2d16-af69f613b625
# get the true, normalized matrix
function compute_At_complete(Œºs::Array{Float64, 1}, œÉs::Array{Float64, 1})
	An = deepcopy(A_complete_unnormalized)
	for p = 1:n_p
        An[:, p] .= (An[:, p] .- Œºs[p]) ./ œÉs[p]
    end
	return collect(An')
end

# ‚ïî‚ïê‚ï° 36da7c1e-5bb1-11eb-2bc9-438dabcf9cc5
# spearman rank for property p
#    true A': true matrix
#    pred A': imputed matrix
#    ids_test: the test ids
#    p: the property
function œÅ_p(ùìÖ::Int,
		     At_complete::Array{Float64, 2},
			 AÃÇt::Array{Number, 2},
		     ids_test::Array{Tuple{Int64,Int64}, 1}
		    )
	@assert size(AÃÇt) == (n_p, n_m)
	
	ids_test_ùìÖ = [(p, m) for (p, m) in ids_test if p == ùìÖ]
	
	# truth and predicted value of the property
	a = [At_complete[p, m] for (p, m) in ids_test_ùìÖ]
	aÃÇ = convert(Array{Float64, 1}, 
		        [AÃÇt[p, m] for (p, m) in ids_test_ùìÖ]
		        )
	return corspearman(a, aÃÇ)
end

# ‚ïî‚ïê‚ï° efc74f24-5ba0-11eb-2c44-6dac87ec534a
md"# hyperparam grid sweep"

# ‚ïî‚ïê‚ï° a269ab26-5ba4-11eb-1001-6703f57f495c
begin
	ks = collect(1:3)                       # ranks
	Œªs = 10.0 .^ range(-1.0, 3.0, length=4) # regularization params
	hyper_params = hp_grid(ks, Œªs)
end

# ‚ïî‚ïê‚ï° 9cf75472-5ba0-11eb-371a-5bc338946b61
# hyperparam sweep
# return optimal hyperparams with min rmsd
function hyperparam_sweep(hyper_params::Array{HyperParam, 1}, 
						  At::Array{Union{Float64, Missing}, 2},
						  ids_train::Array{Tuple{Int64,Int64},1},
						  ids_valid::Array{Tuple{Int64,Int64},1}
						 ) 
	valid_runs = ValidationRun[]
	for hyper_param in hyper_params
		# train on training data
		G, P, glrm, ch = fit_glrm(At, hyper_param, ids_train)
		# impute missing entries
		AÃÇt = impute(glrm)
		# evaluate on validation data
		a = [At[p, m] for (p, m) in ids_valid]
		aÃÇ = [AÃÇt[p, m] for (p, m) in ids_valid]

		push!(valid_runs, ValidationRun(hyper_param, 
										rmsd(a, aÃÇ)
									   )
			  )
	end
	
	return min_rmsd(valid_runs)
end

# ‚ïî‚ïê‚ï° 2009751a-5bae-11eb-158f-a3d9cb98fe24
md"# performance evaluation"

# ‚ïî‚ïê‚ï° 09b74408-5baa-11eb-3735-e9333756f565
struct Result
	# the data
	A::Array{Union{Float64, Missing}, 2}
	# the depolyment model model
	M::Array{Float64, 2}
	P::Array{Float64, 2}
	hp::HyperParam
	# true test data pts
	a::Array{Float64, 1}
	# pred test data pts
	aÃÇ::Array{Float64, 1}
	# pred test data for bias only
	aÃÇb::Array{Float64, 1}
	# gas-wise Spearman rank coeffs
	œÅp::Array{Float64, 1}
	# gas-wise Spearman rank coeffs bias only
	œÅpb::Array{Float64, 1}
end

# ‚ïî‚ïê‚ï° b285e2fe-5ba7-11eb-2e12-83e72bcafa2f
# 1. simulate data collection
# 2. split observed values into train and validation set
# 3. remaining unobserved = test data
# 4. do hyperparam sweep to find optimal hyperparams, judged by validation data
# 5. now that we hv optimal hyper params, retrain on all observed.
# 6. evaluate it on test entries
#   return (true values, pred values)
function run_simulation(Œ∏::Float64)
	###
	#    set up data
	###
	A, Œ∏_true = sim_data_collection(Œ∏)

	# store for later.
	Œºs, œÉs = normalize!(A)

	At = collect(A')
	
	# split into test/validation/train
	ids_obs, ids_unobs = ids_obs_and_unobs(At)
	ids_test = ids_unobs
	@assert(all(ismissing.([At[p, m] for (p, m) in ids_test])))
	ids_train, ids_valid = train_test_split(ids_obs, test_size=0.2, shuffle=true)

	###
	#   hyper-parameter sweep using train/valid data 
	#        to find optimal hyper params (k, Œª)
	###
	opt_valid_run = hyperparam_sweep(hyper_params, At, ids_train, ids_valid)

	###
	#   deployment time: train model on all observed data
	###
	P, M, glrm, ch = fit_glrm(At, opt_valid_run.hyper_param, ids_obs)
	Gb, Mb, glrmb, chb = fit_bias_only_glrm(At, ids_obs)
	
	###
	#   test time: test depolyed model on unobserved entries
	###
	AÃÇt = impute(glrm)
	AÃÇtb = impute(glrmb)

	# compute truth from normalizations
	At_complete = compute_At_complete(Œºs, œÉs)

	# test model on unobserved
	a = [At_complete[p, m] for (p, m) in ids_test]
	aÃÇ = [AÃÇt[p, m] for (p, m) in ids_test]
	aÃÇb = [AÃÇtb[p, m] for (p, m) in ids_test]
	# get spearman ranks for gases

	œÅp = [œÅ_p(p, At_complete, AÃÇt, ids_test) for p = 1:n_p]
	œÅpb = [œÅ_p(p, At_complete, AÃÇtb, ids_test) for p = 1:n_p]
	return Result(A, M, P, opt_valid_run.hyper_param,
		          a, aÃÇ, aÃÇb, œÅp, œÅpb)
end

# ‚ïî‚ïê‚ï° 5d38b414-5f41-11eb-14b9-73a9007fc263
md"# $\theta=0.4$ example"

# ‚ïî‚ïê‚ï° 4f81a520-5f6d-11eb-1960-9918ca4f25e9
res = run_simulation(0.4)

# ‚ïî‚ïê‚ï° 68fe93ae-5f6e-11eb-012a-81378cd15b41
viz_matrix(res.A)

# ‚ïî‚ïê‚ï° 53585188-5f6f-11eb-0fc0-abbd20ee33fe
begin
	# clip values
	da_cutoff = 6.0
	Œ¥ = 0.1
	for üê∂ in [res.a, res.aÃÇ]
		üê∂[üê∂ .< - da_cutoff] .= - da_cutoff
		üê∂[üê∂ .>   da_cutoff] .=   da_cutoff
	end
	
	# parity plot
	figure()
	hexbin(res.a, res.aÃÇ, mincnt=1, bins="log")
	xlabel(L"true $A_{ij}$ (normalized)")
	ylabel(L"predicted $A_{ij}$ (normalized)")
	xlim([-da_cutoff - Œ¥, da_cutoff + Œ¥])
	ylim([-da_cutoff - Œ¥, da_cutoff + Œ¥])
	plot([-da_cutoff, da_cutoff], [-da_cutoff, da_cutoff], 
		linestyle="--", color="gray")
	text(4, -4, 
		@sprintf("hyperparameters:\nk = %d\nŒª = %.2f\n\nperformance:\nœÅ = %.2f\nRMSE = %.2f", res.hp.k, res.hp.Œª, corspearman(res.a, res.aÃÇ), rmsd(res.a, res.aÃÇ)),
		ha="center", va="center"
		)
	colorbar(label="# (COF, adsorption property) pairs")
	gca().set_aspect("equal", "box")
	tight_layout()
	savefig("parity_plot.pdf", format="pdf")
	gcf()
end

# ‚ïî‚ïê‚ï° 74068408-5f70-11eb-02ba-417e847034c4
begin
	figure(figsize=(10, 4.8))
	bar(1:n_p, res.œÅp, label=@sprintf("k = %d, Œª = %.2f", res.hp.k, res.hp.Œª))
	scatter(1:n_p, res.œÅpb, marker="*", zorder=100, s=150, 
		    ec="k", label="k = 0"
		    )
	xticks(1:n_p, [prop_to_label[p] for p in properties], rotation=90)
	ylabel("Spearman's rank\ncorrelation coefficient\n"  * L"$\rho$")
	# text(12.0, 0.9,
	# 	@sprintf("hyperparameters:\nk = %d\nŒª = %.2f", res.hp.k, res.hp.Œª),
	# 	ha="center", va="center"
	# 	)
	legend()
	ylim([0.0, 1.0])
	gcf()
end

# ‚ïî‚ïê‚ï° 8548a48c-5f73-11eb-3d4f-550078ec546a
begin
	Œº = res.M[end, :]
	ids_sort = sortperm(Œº, rev=true)
	
	n_show = 20
	n_space = 3
	
	ids_best  = 1:n_show
	ids_worst = (n_show + n_space + 1):(2 * n_show + n_space + 1)
	
	figure(figsize=(10.0, 4.8))
	bar(ids_best , Œº[ids_sort][1:n_show])
	bar(ids_worst, Œº[ids_sort][end-n_show:end])
	xticks(vcat(ids_best, ids_worst), 
		   vcat(materials[ids_sort][ids_best], materials[ids_sort][ids_worst]),
		   rotation=90
		  )
	xlim([0, 2 * n_show + n_space + 2])
	# ylim([-4.25, 4.25])
	xlabel("COF")
	ylabel(L"material bias, $\mu_i$")
	
	scatter((n_show+1):(n_show+n_space), zeros(3), color="k")
	
	tight_layout()
	savefig("material_bias.pdf", format="pdf")
	gcf()
end

# ‚ïî‚ïê‚ï° b0560c02-5f80-11eb-338b-c9cc48b741af
md"### learn latent space

of materials and properties together.
"

# ‚ïî‚ïê‚ï° ba8ce81e-5f80-11eb-3e39-f942cb6d0d1f
X = hcat(res.M[1:end-1, :], res.P[1:end-1, :])

# ‚ïî‚ïê‚ï° c6caaa48-5f7f-11eb-3853-fdffcd51b2d5
begin
	# input: (a column-major matrix of shape (n_features, n_samples))
	latent_space = umap(X, 2)
	m_vecs = latent_space[:, 1:n_m]
	p_vecs = latent_space[:, (n_m+1):end]
	@assert size(p_vecs) == (2, n_p)
end

# ‚ïî‚ïê‚ï° 8024beae-5f88-11eb-3e97-b7afbbbc6f5c
function viz_prop_latent_space()
	figure(figsize=(10, 10))
	scatter(p_vecs[1, :], p_vecs[2, :], edgecolor="k")
	xlabel("UMAP dimension 1")
	ylabel("UMAP dimension 2")
	texts = []
	for p = 1:n_p
		push!(texts, 
			annotate(prop_to_label[properties[p]], 
				(p_vecs[1, p], p_vecs[2, p]), fontsize=10, ha="center")
			)
	end
	adjustText.adjust_text(texts, force_text=(0.01, 0.01))
	# colorbar(label=prop_to_label[properties[p]], extend="both")
	gca().set_aspect("equal", "box")
	tight_layout()
	gcf()
end

# ‚ïî‚ïê‚ï° ab3a5568-5f88-11eb-373a-2f79bfce3cff
viz_prop_latent_space()

# ‚ïî‚ïê‚ï° 5e72bb6e-5f89-11eb-33c1-472327869ed1
properties

# ‚ïî‚ïê‚ï° 59a72a22-5f82-11eb-1424-0913e7830bc4
function color_latent_material_space(p::Int)
	figure()
	scatter(m_vecs[1, :], m_vecs[2, :], c=A_n[:, p], s=25, 
		vmin=-3.0, vmax=3.0, cmap="PiYG", edgecolor="k")
	xlabel("UMAP dimension 1")
	ylabel("UMAP dimension 2")
	colorbar(label=prop_to_label[properties[p]], extend="both")
	gca().set_aspect("equal", "box")
	tight_layout()
	gcf()
end

# ‚ïî‚ïê‚ï° b0619008-5f86-11eb-11b6-c7a3c4db9fd3
color_latent_material_space(15)

# ‚ïî‚ïê‚ï° 86b00b60-5f89-11eb-071f-bb364af09c2a
color_latent_material_space(12)

# ‚ïî‚ïê‚ï° 55ee1330-6508-11eb-37d1-1973f7e077ed
md"todo: color by void fraction etc."

# ‚ïî‚ïê‚ï° 0cd6cd76-5f6e-11eb-0bf5-2f0ea61ef29b
md"# loop over Œ∏s"

# ‚ïî‚ïê‚ï° 5bbe8438-5f41-11eb-3d16-716bcb25400b
begin
	struct SparseResult
		œÅ::Float64
		œÅb::Float64
		œÅp::Array{Float64, 1}
		œÅpb::Array{Float64, 1}
		k::Int
		Œª::Float64
	end
	
	function run_Œ∏_study(Œ∏::Float64, nb_sims::Int)
		results = SparseResult[]
		for s = 1:nb_sims
			res = run_simulation(Œ∏)
			push!(results, 
				SparseResult(corspearman(res.a, res.aÃÇ),
				             corspearman(res.a, res.aÃÇb),
							 res.œÅp,
							 res.œÅpb,
					         res.hp.k,
							 res.hp.Œª
						     )
				)
		end
		return results
	end
	
	Œ∏s = 0.1:0.1:0.3
	Œ∏results = [run_Œ∏_study(Œ∏, 3) for Œ∏ in Œ∏s]
end

# ‚ïî‚ïê‚ï° c7aa89b0-5f93-11eb-0503-5565bba9cb86
function viz_œÅp_vsŒ∏()
	fig, axs = plt.subplots(ncols=n_p, figsize=(25, 4.0), sharex=true)
		# gridspec_kw=Dict("hspace" => 0.25), sharex=true)
	for (p, ax) in enumerate(axs)
		if p == 1
			ax.set_ylabel("Spearman's rank\ncorrelation coefficient\n" * L"$\rho$")
		else
			ax.spines["left"].set_visible(false)
			# ax.yaxis.set_visible(false)
			ax.set_yticklabels([])
		end
		if p == floor(Int, n_p/2)
			ax.set_xlabel(L"target fraction observed entries, $\theta$")
		end
		ax.spines["right"].set_visible(false)
		ax.spines["bottom"].set_position("zero")
		ax.spines["top"].set_visible(false)
		ax.set_ylim([0.0, 1.0])
		
		# one per Œ∏
		œÅ_avg = [mean([res.œÅp[p] for res in Œ∏results[i]]) for i = 1:length(Œ∏s)]
		œÅ_std = [std([res.œÅp[p] for res in Œ∏results[i]]) for i = 1:length(Œ∏s)]
		œÅb_avg = [mean([res.œÅpb[p] for res in Œ∏results[i]]) for i = 1:length(Œ∏s)]
		œÅb_std = [std([res.œÅpb[p] for res in Œ∏results[i]]) for i = 1:length(Œ∏s)]
		
		ax.plot(Œ∏s, œÅ_avg, marker="o")
		ax.fill_between(Œ∏s, œÅ_avg .- œÅ_std, œÅ_avg .+ œÅ_std, alpha=0.3)
		
		ax.plot(Œ∏s, œÅb_avg, marker="o", linestyle="--")
		ax.fill_between(Œ∏s, œÅb_avg .- œÅb_std, œÅb_avg .+ œÅb_std, alpha=0.3)
		
		ax.set_title(prop_to_label[properties[p]], fontsize=14, rotation=90)
		ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])
	end
	for ax in axs
		ax.set_xticks([0.0, 0.5, 1.0])
	end
	
	tight_layout()
	savefig("rho_vs_theta.pdf", format="pdf")
    
	gcf()
end

# ‚ïî‚ïê‚ï° 56bb9b5c-5f95-11eb-0d3f-97cd4b7a48a0
viz_œÅp_vsŒ∏()

# ‚ïî‚ïê‚ï° 0830c1de-5f9e-11eb-132a-77b3084102b2
begin
	dfŒ∏ = DataFrame(Œ∏=Float64[], k=Int[], Œª=Float64[])
	for i = 1:length(Œ∏s)
		for r in Œ∏results[i]
			push!(dfŒ∏, [Œ∏s[i], r.k, r.Œª])
		end
	end
	CSV.write("theta_k_lambda_table.csv", dfŒ∏)
	dfŒ∏
end

# ‚ïî‚ïê‚ï° Cell order:
# ‚ï†‚ïê92083d94-5b82-11eb-2274-ed62139bbf2d
# ‚ïü‚îÄae415fa4-5b82-11eb-0051-072097bb0439
# ‚ï†‚ïêb3deec9e-5b82-11eb-0e37-abd2ac9d4b44
# ‚ïü‚îÄbf9ed538-5b82-11eb-1198-3d35a209c5c0
# ‚ï†‚ïêc5d42b2e-5b82-11eb-0631-35efb6b0800c
# ‚ïü‚îÄ6713990c-5b8d-11eb-2196-7182f36cad59
# ‚ï†‚ïê2931005c-5b8d-11eb-2375-5dacf441be72
# ‚ï†‚ïêa21ac3b8-5ba1-11eb-2d70-bdf4b395f563
# ‚ïü‚îÄ1d363324-5b8f-11eb-2c78-6980a0d5f110
# ‚ï†‚ïê2366b3cc-5b8f-11eb-07e4-61cbc97d5480
# ‚ïü‚îÄ6236b296-5f60-11eb-3aa7-5188433b3906
# ‚ï†‚ïê5ae47630-5f64-11eb-39f8-654f8d277674
# ‚ïü‚îÄ6ef474cc-5b90-11eb-2fe2-87bc7b48f5b7
# ‚ï†‚ïê8a3c55ae-5ba4-11eb-3354-f9a8feaa7e91
# ‚ï†‚ïê1d745ea2-5ba5-11eb-274a-4ff7a65b0cb6
# ‚ï†‚ïêcc771288-5ba6-11eb-1792-9dfc54c58a8c
# ‚ï†‚ïêf7158eea-5ba4-11eb-17cc-d57c477cec39
# ‚ï†‚ïê8152d710-5b90-11eb-39f5-45d81aa298ab
# ‚ï†‚ïê21995e36-5f69-11eb-0a95-13d0136099df
# ‚ïü‚îÄe2dd554c-5baf-11eb-1b49-654d19bedecc
# ‚ï†‚ïê168d4c44-5bb3-11eb-2d16-af69f613b625
# ‚ï†‚ïê36da7c1e-5bb1-11eb-2bc9-438dabcf9cc5
# ‚ïü‚îÄefc74f24-5ba0-11eb-2c44-6dac87ec534a
# ‚ï†‚ïêa269ab26-5ba4-11eb-1001-6703f57f495c
# ‚ï†‚ïê9cf75472-5ba0-11eb-371a-5bc338946b61
# ‚ïü‚îÄ2009751a-5bae-11eb-158f-a3d9cb98fe24
# ‚ï†‚ïê09b74408-5baa-11eb-3735-e9333756f565
# ‚ï†‚ïêb285e2fe-5ba7-11eb-2e12-83e72bcafa2f
# ‚ïü‚îÄ5d38b414-5f41-11eb-14b9-73a9007fc263
# ‚ï†‚ïê4f81a520-5f6d-11eb-1960-9918ca4f25e9
# ‚ï†‚ïê68fe93ae-5f6e-11eb-012a-81378cd15b41
# ‚ï†‚ïê53585188-5f6f-11eb-0fc0-abbd20ee33fe
# ‚ï†‚ïê74068408-5f70-11eb-02ba-417e847034c4
# ‚ï†‚ïê8548a48c-5f73-11eb-3d4f-550078ec546a
# ‚ïü‚îÄb0560c02-5f80-11eb-338b-c9cc48b741af
# ‚ï†‚ïêba8ce81e-5f80-11eb-3e39-f942cb6d0d1f
# ‚ï†‚ïêc6caaa48-5f7f-11eb-3853-fdffcd51b2d5
# ‚ï†‚ïê8024beae-5f88-11eb-3e97-b7afbbbc6f5c
# ‚ï†‚ïêab3a5568-5f88-11eb-373a-2f79bfce3cff
# ‚ï†‚ïê5e72bb6e-5f89-11eb-33c1-472327869ed1
# ‚ï†‚ïê59a72a22-5f82-11eb-1424-0913e7830bc4
# ‚ï†‚ïêb0619008-5f86-11eb-11b6-c7a3c4db9fd3
# ‚ï†‚ïê86b00b60-5f89-11eb-071f-bb364af09c2a
# ‚ïü‚îÄ55ee1330-6508-11eb-37d1-1973f7e077ed
# ‚ïü‚îÄ0cd6cd76-5f6e-11eb-0bf5-2f0ea61ef29b
# ‚ï†‚ïê5bbe8438-5f41-11eb-3d16-716bcb25400b
# ‚ï†‚ïêc7aa89b0-5f93-11eb-0503-5565bba9cb86
# ‚ï†‚ïê56bb9b5c-5f95-11eb-0d3f-97cd4b7a48a0
# ‚ï†‚ïê0830c1de-5f9e-11eb-132a-77b3084102b2
